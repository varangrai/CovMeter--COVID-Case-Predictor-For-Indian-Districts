{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Encoder decoder.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENninCGa0lI5"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_U6-8dUeGeO"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import statistics \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "print(tf.__version__)\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ryRkKRf1pd0"
      },
      "source": [
        "#load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUrJiHCzRP-R"
      },
      "source": [
        "dicti={\n",
        " 'Andhra_Pradesh':[0,13],\n",
        " 'Arunachal_Pradesh':[13,38],\n",
        " 'Assam':[38,71],\n",
        " 'Bihar':[71,109],\n",
        " 'Chattisgarh':[109,137],\n",
        " 'Goa':[137,139],\n",
        " 'Gujarat':[139,172],\n",
        " 'Haryana':[172,194],\n",
        " 'Himanchal_Pradesh':[194,206],\n",
        " 'Jharkhand':[206,230],\n",
        " 'Karnataka':[230,260],\n",
        " 'Kerala':[260,274],\n",
        " 'Madhya_Pradesh':[274,329],\n",
        " 'Maharashtra':[329,365],\n",
        " 'Manipur':[365,381],\n",
        " 'Meghalaya':[381,392],\n",
        " 'Mizoram':[392,400],\n",
        " 'Nagaland':[400,412],\n",
        " 'Odisha':[412,442],\n",
        " 'Punjab':[442,464],\n",
        " 'Rajasthan':[464,497],\n",
        " 'Sikkim':[497,501],\n",
        " 'Tamil_Nadu':[501,539],\n",
        " 'Telangana':[539,572],\n",
        " 'Tripura':[572,580],\n",
        " 'Uttar_Pradesh':[580,655],\n",
        " 'Uttarakhand':[655,668],\n",
        " 'West_Bengal':[668,691],\n",
        " 'Andaman':[691,694],\n",
        " 'Chandigarh':[694,695],\n",
        " 'Daman':[695,698],\n",
        " 'Jammu':[698,718],\n",
        " 'Ladakh':[718,720],\n",
        " 'Lakshadweep':[720,721],\n",
        " 'Delhi':[721,732],\n",
        " 'Puducherry':[732,736]\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-qqu4uAeB29",
        "outputId": "8e983a60-2193-4344-cdd3-32e678dd932b"
      },
      "source": [
        "!gdown --id 1pQzv9GfJEak6EodyEgNnLGJZpt0iweq9\n",
        "data=np.load('/content/3ddistrict.npy')\n",
        "data.shape\n",
        "# !gdown --id 1NBymn3rsbOLt5DQcr0bX1Ln08MNrazLb\n",
        "# datas=np.load('/content/3dstate.npy')\n",
        "# datas.shape\n",
        "print('number of nans: ',np.count_nonzero(np.isnan(data)))\n",
        "for dis in range(736):\n",
        "  for feat in range(5):\n",
        "    for day in range(0,357):\n",
        "      if np.isnan(data[feat,day,dis]):\n",
        "        for dist in range(10):\n",
        "          l=day-dist\n",
        "          r=day+dist\n",
        "          if ~np.isnan(data[feat,l,dis]): \n",
        "            data[feat,day,dis]=data[feat,l,dis]\n",
        "            break\n",
        "          elif ~np.isnan(data[feat,r,dis]): \n",
        "            data[feat,day,dis]=data[feat,r,dis]\n",
        "            break\n",
        "\n",
        "      \n",
        "\n",
        "      \n",
        "print('number of nans',np.count_nonzero(np.isnan(data)))\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(np.expand_dims(data.flatten('F'),1))\n",
        "data2=np.zeros((5,357,736))\n",
        "for dist in range(736):\n",
        "  temp=data[:,:,dist]\n",
        "  # print(temp.shape)\n",
        "  data2[:,:,dist]=scaler.transform(temp)\n",
        "  # data2[:,4,dist]= data[:,4,dist]\n",
        "  # data2[:,:,dist]=temp/1000\n",
        "data2=data2.swapaxes(0,1)\n",
        "print('shape of data: ',data2.shape)\n",
        "data3=data2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1pQzv9GfJEak6EodyEgNnLGJZpt0iweq9\n",
            "To: /content/3ddistrict.npy\n",
            "\r0.00B [00:00, ?B/s]\r8.91MB [00:00, 89.0MB/s]\r10.5MB [00:00, 92.8MB/s]\n",
            "number of nans:  69\n",
            "number of nans 0\n",
            "shape of data:  (357, 5, 736)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvoeW16Tf9t3"
      },
      "source": [
        "data3=data3[:,:,329:365]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Gj3BBTHgYvQ",
        "outputId": "fb8356b1-2d66-47ce-c131-34627862511f"
      },
      "source": [
        "data3.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(357, 5, 736)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZrqdQ3M2Dzs"
      },
      "source": [
        "#Data hyperparamets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgvxzr2rfvW5"
      },
      "source": [
        "batch_size = 32\n",
        "shuffle_buffer_size = 1000\n",
        "traindays=200\n",
        "num_of_districts=736\n",
        "window_size=21  #same as n_past\n",
        "n_past = 21\n",
        "n_future = 7\n",
        "n_features = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jseWsBr72IHb"
      },
      "source": [
        "#Window data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-m1oh7lfqVC"
      },
      "source": [
        "window_size=n_past\n",
        "def windowed_dataset(series, window_size, batch_size, shuffle_buffer,test):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(series)\n",
        "  dataset = dataset.window(window_size + n_future, shift=1, drop_remainder=True)\n",
        "  dataset = dataset.flat_map(lambda window: window.batch(window_size + n_future))\n",
        "  if test : dataset = dataset.map(lambda window: (window[:-n_future], window[-n_future:]))\n",
        "  else:\n",
        "    dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-n_future], window[-n_future:]))\n",
        "  return dataset\n",
        "test=data3[traindays:,:,:]\n",
        "data2=data3[:traindays,:,:]\n",
        "X,Y=[],[]\n",
        "for dist in range(num_of_districts):\n",
        "  temp = data2[:,:,dist]\n",
        "  dst = windowed_dataset(temp, window_size, 1, shuffle_buffer_size,False)\n",
        "  for x,y in dst:\n",
        "    X.append(x.numpy())\n",
        "    Y.append(y.numpy()) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIwv2Oy8gm87",
        "outputId": "ab6e7d9a-13a0-4927-d932-1e9d9870b231"
      },
      "source": [
        "X_test,Y_test=[],[]\n",
        "X_test_sw,Y_test_sw=[],[]\n",
        "for dist in range(num_of_districts):\n",
        "  temp = test[:,:,dist]\n",
        "  dst = windowed_dataset(temp, window_size, 1, shuffle_buffer_size,True)\n",
        "  x_dist,y_dist=[],[]\n",
        "  for x,y in dst:\n",
        "    X_test.append(x.numpy())\n",
        "    Y_test.append(y.numpy())\n",
        "    x_dist.append(x.numpy())\n",
        "    y_dist.append(y.numpy())\n",
        "  X_test_sw.append(x_dist)\n",
        "  Y_test_sw.append(y_dist)\n",
        "X_train=np.squeeze(np.array(X))\n",
        "Y_train=np.squeeze(np.array(Y))\n",
        "X_test=np.squeeze(np.array(X_test))\n",
        "Y_test=np.squeeze(np.array(Y_test))\n",
        "print(X_test.shape,Y_test.shape)\n",
        "print(X_train.shape,Y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(95680, 21, 5) (95680, 7, 5)\n",
            "(127328, 21, 5) (127328, 7, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gx5wiSfhKv9",
        "outputId": "a80a8df7-0231-4a69-a37f-53e05a495fe2"
      },
      "source": [
        "np.array(X_test_sw).shape\n",
        "np.array(Y_test_sw).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(736, 130, 7, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n3IeEgY0DiN"
      },
      "source": [
        "batch_size = 32\n",
        "shuffle_buffer_size = 1000\n",
        "traindays=200\n",
        "num_of_districts=36\n",
        "window_size=21  #same as n_past\n",
        "n_past = 21\n",
        "n_future = 7\n",
        "n_features = 2\n",
        "!gdown --id 1VSzHDBC8Xp4PQD-MlWXQAOMUHCsVzRCQ\n",
        "!gdown --id 1uTXa84C-kX6XZk2QBoadED-fq4HlfeUw\n",
        "!gdown --id 1Jjeix6c0Oh5g1I0xkRMKCgoapLdVVMHE\n",
        "!gdown --id 1LkQW3U4nAcl8YG5R_E7wj5kiTpBtN7nc\n",
        "X_train=np.load('/content/X_train.npy')\n",
        "Y_train=np.load('/content/Y_train.npy')\n",
        "X_test=np.load('/content/X_test.npy')\n",
        "Y_test=np.load('/content/Y_test.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pamwFo21hpGt",
        "outputId": "f5b26b91-2679-4a3e-ec20-a846b404fa4e"
      },
      "source": [
        "X_temptrain=X_train[:,:,[3,4]]  #choose active cases and state id\n",
        "Y_temptrain=np.expand_dims(Y_train[:,:,3],2)\n",
        "Y_temptest=np.expand_dims(Y_test[:,:,3],2)\n",
        "X_temptest=X_test[:,:,[3,4]]\n",
        "print(np.array(X_temptest).shape,np.array(Y_temptest).shape)\n",
        "print(np.array(X_temptrain).shape,np.array(Y_temptrain).shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(95680, 21, 2) (95680, 7, 1)\n",
            "(127328, 21, 2) (127328, 7, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nv04Vd8vIhr"
      },
      "source": [
        "#LSTM encoder decoder\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0jL4994hUCQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6256fd17-925a-462a-aad7-01d441e9c5dc"
      },
      "source": [
        "encoder_inputs = tf.keras.layers.Input(shape=(n_past, n_features))\n",
        "encoder_l1 = tf.keras.layers.LSTM(32,return_sequences = True, return_state=True)\n",
        "encoder_outputs1 = encoder_l1(encoder_inputs)\n",
        "encoder_states1 = encoder_outputs1[1:]\n",
        "encoder_l2 = tf.keras.layers.LSTM(32, return_state=True)\n",
        "encoder_outputs2 = encoder_l2(encoder_outputs1[0])\n",
        "encoder_states2 = encoder_outputs2[1:]\n",
        "decoder_inputs = tf.keras.layers.RepeatVector(n_future)(encoder_outputs2[0])\n",
        "decoder_l1 = tf.keras.layers.LSTM(32, return_sequences=True)(decoder_inputs,initial_state = encoder_states1)\n",
        "decoder_l2 = tf.keras.layers.LSTM(32, return_sequences=True)(decoder_l1,initial_state = encoder_states2)\n",
        "decoder_outputs2 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1))(decoder_l2)\n",
        "model_e2d2 = tf.keras.models.Model(encoder_inputs,decoder_outputs2)\n",
        "model_e2d2.summary()\n",
        "def mean_absolute_percentage_error2(y_true, y_pred): \n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "for epochno in range(10):\n",
        "  print(\"Epoch number: {}\".format(epochno))\n",
        "  model_e2d2.compile(loss=tf.keras.losses.Huber(),optimizer='adam'\n",
        "                ,metrics=[tf.keras.losses.MeanAbsolutePercentageError()],run_eagerly=True)\n",
        "  model_e2d2.fit(X_temptrain,Y_temptrain,batch_size=128, epochs=1)\n",
        "  model_e2d2.save_weights(\"weights-{}.h5\".format(epochno))\n",
        "  predictions=model_e2d2.predict(X_temptest)\n",
        "  print('Performance on test data: ',mean_absolute_percentage_error2(scaler.inverse_transform(predictions.reshape(-1,1)),\n",
        "                                          scaler.inverse_transform(Y_temptest.reshape(-1,1))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_14\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_16 (InputLayer)           [(None, 21, 2)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_48 (LSTM)                  [(None, 21, 32), (No 4480        input_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_49 (LSTM)                  [(None, 32), (None,  8320        lstm_48[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_15 (RepeatVector) (None, 7, 32)        0           lstm_49[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_50 (LSTM)                  (None, 7, 32)        8320        repeat_vector_15[0][0]           \n",
            "                                                                 lstm_48[0][1]                    \n",
            "                                                                 lstm_48[0][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_51 (LSTM)                  (None, 7, 32)        8320        lstm_50[0][0]                    \n",
            "                                                                 lstm_49[0][1]                    \n",
            "                                                                 lstm_49[0][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_14 (TimeDistri (None, 7, 1)         33          lstm_51[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 29,473\n",
            "Trainable params: 29,473\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch number: 0\n",
            "49/49 [==============================] - 3s 61ms/step - loss: 0.0067 - mean_absolute_percentage_error: 60.8804\n",
            "Performance on test data:  77.67064702158765\n",
            "Epoch number: 1\n",
            "49/49 [==============================] - 3s 60ms/step - loss: 9.0078e-04 - mean_absolute_percentage_error: 21.3067\n",
            "Performance on test data:  135.44778155385282\n",
            "Epoch number: 2\n",
            "49/49 [==============================] - 3s 61ms/step - loss: 7.8844e-04 - mean_absolute_percentage_error: 16.3845\n",
            "Performance on test data:  67.4077499655723\n",
            "Epoch number: 3\n",
            "49/49 [==============================] - 3s 61ms/step - loss: 6.6618e-04 - mean_absolute_percentage_error: 14.2210\n",
            "Performance on test data:  258.76795522551794\n",
            "Epoch number: 4\n",
            "49/49 [==============================] - 3s 61ms/step - loss: 7.7183e-04 - mean_absolute_percentage_error: 17.2508\n",
            "Performance on test data:  65.72701698002838\n",
            "Epoch number: 5\n",
            "49/49 [==============================] - 3s 61ms/step - loss: 6.2564e-04 - mean_absolute_percentage_error: 13.4402\n",
            "Performance on test data:  251.89442584056277\n",
            "Epoch number: 6\n",
            "49/49 [==============================] - 3s 61ms/step - loss: 6.4978e-04 - mean_absolute_percentage_error: 16.3315\n",
            "Performance on test data:  93.27239444246948\n",
            "Epoch number: 7\n",
            "49/49 [==============================] - 3s 61ms/step - loss: 5.1865e-04 - mean_absolute_percentage_error: 14.4722\n",
            "Performance on test data:  167.96132092196402\n",
            "Epoch number: 8\n",
            "49/49 [==============================] - 3s 61ms/step - loss: 6.5434e-04 - mean_absolute_percentage_error: 14.4472\n",
            "Performance on test data:  63.62381272732773\n",
            "Epoch number: 9\n",
            "49/49 [==============================] - 3s 61ms/step - loss: 6.3813e-04 - mean_absolute_percentage_error: 15.4430\n",
            "Performance on test data:  68.55075736144342\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyk8bBS0vNjd"
      },
      "source": [
        "#Bidirectional LSTM encoder decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUvMPJFcw9Ws",
        "outputId": "b0dc524f-4296-4552-c956-e6a97bf1afb6"
      },
      "source": [
        "encoder_inputs = tf.keras.layers.Input(shape=(n_past, n_features))\n",
        "encoder_l1 =  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32,return_sequences = True, return_state=True))\n",
        "encoder_outputs1 = encoder_l1(encoder_inputs)\n",
        "encoder_states1 = encoder_outputs1[1:]\n",
        "encoder_l2 =  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM( 32, return_state=True))\n",
        "encoder_outputs2 = encoder_l2(encoder_outputs1[0])\n",
        "encoder_states2 = encoder_outputs2[1:]\n",
        "decoder_inputs = tf.keras.layers.RepeatVector(n_future)(encoder_outputs2[0])\n",
        "decoder_l1 =  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True))(decoder_inputs,initial_state = encoder_states1)\n",
        "decoder_l2 =  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True))(decoder_l1,initial_state = encoder_states2)\n",
        "decoder_outputs2 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1))(decoder_l2)\n",
        "model_e2d2 = tf.keras.models.Model(encoder_inputs,decoder_outputs2)\n",
        "model_e2d2.summary()\n",
        "def mean_absolute_percentage_error2(y_true, y_pred): \n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "for epochno in range(30):\n",
        "  print(\"Epoch number: {}\".format(epochno))\n",
        "  model_e2d2.compile(loss=tf.keras.losses.Huber(),optimizer='adam'\n",
        "                ,metrics=[tf.keras.losses.MeanAbsolutePercentageError()],run_eagerly=True)\n",
        "  model_e2d2.fit(X_temptrain,Y_temptrain,batch_size=128, epochs=1)\n",
        "  model_e2d2.save_weights(\"/content/Model1/weights-{}.h5\".format(epochno))\n",
        "  predictions=model_e2d2.predict(X_temptest)\n",
        "  print('Performance on test data: ',mean_absolute_percentage_error2(scaler.inverse_transform(predictions.reshape(-1,1)),\n",
        "                                          scaler.inverse_transform(Y_temptest.reshape(-1,1))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_18\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_20 (InputLayer)           [(None, 21, 2)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_70 (Bidirectional [(None, 21, 64), (No 8960        input_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_71 (Bidirectional [(None, 64), (None,  24832       bidirectional_70[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_19 (RepeatVector) (None, 7, 64)        0           bidirectional_71[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_72 (Bidirectional (None, 7, 64)        24832       repeat_vector_19[0][0]           \n",
            "                                                                 bidirectional_70[0][1]           \n",
            "                                                                 bidirectional_70[0][2]           \n",
            "                                                                 bidirectional_70[0][3]           \n",
            "                                                                 bidirectional_70[0][4]           \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_73 (Bidirectional (None, 7, 64)        24832       bidirectional_72[0][0]           \n",
            "                                                                 bidirectional_71[0][1]           \n",
            "                                                                 bidirectional_71[0][2]           \n",
            "                                                                 bidirectional_71[0][3]           \n",
            "                                                                 bidirectional_71[0][4]           \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_18 (TimeDistri (None, 7, 1)         65          bidirectional_73[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 83,521\n",
            "Trainable params: 83,521\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch number: 0\n",
            "995/995 [==============================] - 97s 97ms/step - loss: 8.9472e-04 - mean_absolute_percentage_error: 17.9848\n",
            "Performance on test data:  105.95757015604154\n",
            "Epoch number: 1\n",
            "995/995 [==============================] - 97s 98ms/step - loss: 2.5767e-04 - mean_absolute_percentage_error: 10.5300\n",
            "Performance on test data:  1001.0374725060558\n",
            "Epoch number: 2\n",
            "995/995 [==============================] - 98s 98ms/step - loss: 2.5421e-04 - mean_absolute_percentage_error: 10.5140\n",
            "Performance on test data:  49.22929885982511\n",
            "Epoch number: 3\n",
            "995/995 [==============================] - 97s 98ms/step - loss: 2.2356e-04 - mean_absolute_percentage_error: 8.7122\n",
            "Performance on test data:  37.75372641270816\n",
            "Epoch number: 4\n",
            "995/995 [==============================] - 98s 99ms/step - loss: 2.1479e-04 - mean_absolute_percentage_error: 8.0538\n",
            "Performance on test data:  39.407696313892835\n",
            "Epoch number: 5\n",
            "995/995 [==============================] - 98s 98ms/step - loss: 2.3430e-04 - mean_absolute_percentage_error: 9.1620\n",
            "Performance on test data:  191.18913592763022\n",
            "Epoch number: 6\n",
            "995/995 [==============================] - 97s 97ms/step - loss: 1.8364e-04 - mean_absolute_percentage_error: 7.6302\n",
            "Performance on test data:  31.58523627289152\n",
            "Epoch number: 7\n",
            "995/995 [==============================] - 96s 97ms/step - loss: 1.8391e-04 - mean_absolute_percentage_error: 7.2615\n",
            "Performance on test data:  50.23967422107797\n",
            "Epoch number: 8\n",
            "995/995 [==============================] - 100s 100ms/step - loss: 1.7935e-04 - mean_absolute_percentage_error: 7.8620\n",
            "Performance on test data:  385.57073733182665\n",
            "Epoch number: 9\n",
            "995/995 [==============================] - 100s 101ms/step - loss: 1.7061e-04 - mean_absolute_percentage_error: 7.3265\n",
            "Performance on test data:  52.34952243911071\n",
            "Epoch number: 10\n",
            "995/995 [==============================] - 100s 101ms/step - loss: 1.5353e-04 - mean_absolute_percentage_error: 7.1664\n",
            "Performance on test data:  136.53333129148504\n",
            "Epoch number: 11\n",
            "995/995 [==============================] - 102s 102ms/step - loss: 1.5431e-04 - mean_absolute_percentage_error: 7.1607\n",
            "Performance on test data:  30.134901857622943\n",
            "Epoch number: 12\n",
            "995/995 [==============================] - 99s 99ms/step - loss: 1.4983e-04 - mean_absolute_percentage_error: 6.9960\n",
            "Performance on test data:  112.35115557031725\n",
            "Epoch number: 13\n",
            "995/995 [==============================] - 101s 102ms/step - loss: 1.6318e-04 - mean_absolute_percentage_error: 7.6420\n",
            "Performance on test data:  34.162181901479535\n",
            "Epoch number: 14\n",
            "995/995 [==============================] - 99s 99ms/step - loss: 1.5166e-04 - mean_absolute_percentage_error: 6.8180\n",
            "Performance on test data:  115.5919653043088\n",
            "Epoch number: 15\n",
            "995/995 [==============================] - 98s 99ms/step - loss: 1.3970e-04 - mean_absolute_percentage_error: 6.9247\n",
            "Performance on test data:  86.69902763938127\n",
            "Epoch number: 16\n",
            "995/995 [==============================] - 98s 98ms/step - loss: 1.3493e-04 - mean_absolute_percentage_error: 6.7028\n",
            "Performance on test data:  156.13242714832109\n",
            "Epoch number: 17\n",
            "995/995 [==============================] - 97s 98ms/step - loss: 1.3178e-04 - mean_absolute_percentage_error: 7.0661\n",
            "Performance on test data:  65.60967074707993\n",
            "Epoch number: 18\n",
            "995/995 [==============================] - 97s 97ms/step - loss: 1.3661e-04 - mean_absolute_percentage_error: 5.9852\n",
            "Performance on test data:  26.72063188854826\n",
            "Epoch number: 19\n",
            "995/995 [==============================] - 97s 97ms/step - loss: 1.3642e-04 - mean_absolute_percentage_error: 6.1559\n",
            "Performance on test data:  344.7379983915913\n",
            "Epoch number: 20\n",
            "995/995 [==============================] - 97s 97ms/step - loss: 1.2331e-04 - mean_absolute_percentage_error: 7.4100\n",
            "Performance on test data:  131.88108775043386\n",
            "Epoch number: 21\n",
            "995/995 [==============================] - 97s 98ms/step - loss: 1.2960e-04 - mean_absolute_percentage_error: 7.4337\n",
            "Performance on test data:  36.28833640597467\n",
            "Epoch number: 22\n",
            "995/995 [==============================] - 97s 97ms/step - loss: 1.4399e-04 - mean_absolute_percentage_error: 6.0911\n",
            "Performance on test data:  28.662693494053592\n",
            "Epoch number: 23\n",
            "995/995 [==============================] - 96s 97ms/step - loss: 1.3454e-04 - mean_absolute_percentage_error: 6.5293\n",
            "Performance on test data:  33.67040359166156\n",
            "Epoch number: 24\n",
            "995/995 [==============================] - 97s 97ms/step - loss: 1.4331e-04 - mean_absolute_percentage_error: 6.1830\n",
            "Performance on test data:  38.79760449647879\n",
            "Epoch number: 25\n",
            "995/995 [==============================] - 97s 97ms/step - loss: 1.3097e-04 - mean_absolute_percentage_error: 6.6004\n",
            "Performance on test data:  96.08376651836568\n",
            "Epoch number: 26\n",
            "995/995 [==============================] - 97s 97ms/step - loss: 1.3470e-04 - mean_absolute_percentage_error: 7.0986\n",
            "Performance on test data:  38.77821578765867\n",
            "Epoch number: 27\n",
            "995/995 [==============================] - 97s 97ms/step - loss: 1.2605e-04 - mean_absolute_percentage_error: 6.4823\n",
            "Performance on test data:  73.29267108531238\n",
            "Epoch number: 28\n",
            "995/995 [==============================] - 96s 97ms/step - loss: 1.0950e-04 - mean_absolute_percentage_error: 5.9490\n",
            "Performance on test data:  1623.2722024390005\n",
            "Epoch number: 29\n",
            "995/995 [==============================] - 96s 96ms/step - loss: 1.1179e-04 - mean_absolute_percentage_error: 7.2344\n",
            "Performance on test data:  30.663754761700112\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qC--g872ILIp",
        "outputId": "c04889ea-b928-4e05-84f3-8a0dd6710879"
      },
      "source": [
        "!gdown --id 1-XU-T_fWIEUITd1bBFTz2x7QFUlJStgq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-XU-T_fWIEUITd1bBFTz2x7QFUlJStgq\n",
            "To: /content/weights-5_28.4mape21_7.h5\n",
            "\r  0% 0.00/392k [00:00<?, ?B/s]\r100% 392k/392k [00:00<00:00, 56.3MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZG2-59BQ0J6"
      },
      "source": [
        "!pip install tensorflow-addons\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "encoder_inputs = tf.keras.layers.Input(shape=(n_past, n_features))\n",
        "encoder_l1 =  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32,return_sequences = True, return_state=True))\n",
        "encoder_outputs1 = encoder_l1(encoder_inputs)\n",
        "encoder_states1 = encoder_outputs1[1:]\n",
        "encoder_l2 =  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM( 32, return_state=True))\n",
        "encoder_outputs2 = encoder_l2(encoder_outputs1[0])\n",
        "encoder_states2 = encoder_outputs2[1:]\n",
        "decoder_inputs = tf.keras.layers.RepeatVector(n_future)(encoder_outputs2[0])\n",
        "decoder_l1 =  tf.keras.layers.Bidirectional(tf.keras.layers.RNN(tfa.rnn.PeepholeLSTMCell(32),return_sequences = True))(decoder_inputs,initial_state = encoder_states1)\n",
        "decoder_l2 =  tf.keras.layers.Bidirectional(tf.keras.layers.RNN( tfa.rnn.PeepholeLSTMCell(32),return_sequences=True))(decoder_l1,initial_state = encoder_states2)\n",
        "decoder_outputs2 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1))(decoder_l2)\n",
        "model_e2d2 = tf.keras.models.Model(encoder_inputs,decoder_outputs2)\n",
        "model_e2d2.summary()\n",
        "def mean_absolute_percentage_error2(y_true, y_pred): \n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "for epochno in range(30):\n",
        "  print(\"Epoch number: {}\".format(epochno))\n",
        "  model_e2d2.compile(loss=tf.keras.losses.Huber(),optimizer='adam'\n",
        "                ,metrics=[tf.keras.losses.MeanAbsolutePercentageError()],run_eagerly=True)\n",
        "  model_e2d2.fit(X_temptrain,Y_temptrain,batch_size=128, epochs=1)\n",
        "  # model_e2d2.save_weights(\"weights-{}.h5\".format(epochno))\n",
        "  predictions=model_e2d2.predict(X_temptest)\n",
        "  print('Performance on test data: ',mean_absolute_percentage_error2(scaler.inverse_transform(predictions.reshape(-1,1)),\n",
        "                                          scaler.inverse_transform(Y_temptest.reshape(-1,1))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cpWSucbnhyO",
        "outputId": "277ea279-3519-464f-c7b1-311906c91b83"
      },
      "source": [
        "X_test_sw=np.array(X_test_sw)\n",
        "Y_test_sw=np.array(Y_test_sw)\n",
        "print(Y_test_sw.shape,\n",
        "X_test_sw.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(736, 130, 7) (736, 130, 21, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFF2n7UBqQM9"
      },
      "source": [
        "X_test_sw=X_test_sw[:,:,:,[3,4]]\n",
        "Y_test_sw=Y_test_sw[:,:,:,3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xU-aoxwzo-Kx",
        "outputId": "5f1c39d3-b982-4ab1-e35b-77493535c11e"
      },
      "source": [
        "x=X_test_sw[1:10]\n",
        "print(x.shape,\n",
        "x.shape)\n",
        "value=[1,9]\n",
        "x=X_test_sw[value[0]:value[1]].reshape(X_test_sw[value[0]:value[1]].shape[0]*X_test_sw[value[0]:value[1]].shape[1],21,5)\n",
        "print(x.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9, 130, 21, 5) (9, 130, 21, 5)\n",
            "(1040, 21, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bEwMSldaSV1",
        "outputId": "ba4acd47-98db-4fbf-89f1-4a90a9e5dd4f"
      },
      "source": [
        "def mean_absolute_percentage_error(y_true, y_pred): \n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "l=[]\n",
        "# predictions_rs =model_e2d2.predict(X_temptest)\n",
        "for key, value in dicti.items():\n",
        "  x=X_test_sw[value[0]:value[1]].reshape(X_test_sw[value[0]:value[1]].shape[0]*X_test_sw[value[0]:value[1]].shape[1],21,2)\n",
        "  y=Y_test_sw[value[0]:value[1]]\n",
        "  predictions=model_e2d2.predict(x)\n",
        "  mapes=mean_absolute_percentage_error(scaler.inverse_transform(predictions.reshape(-1,1)),\n",
        "                                          scaler.inverse_transform(y.reshape(-1,1)))\n",
        "  print('Mape for {} is {}'.format(key,mapes))\n",
        "np.sort(np.array(l).astype(int))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mape for Andhra_Pradesh is 18.7102917497113\n",
            "Mape for Arunachal_Pradesh is 70.17960074474192\n",
            "Mape for Assam is 40.260853960802464\n",
            "Mape for Bihar is 23.726293331788284\n",
            "Mape for Chattisgarh is 38.458527446461375\n",
            "Mape for Goa is 54.31766942908578\n",
            "Mape for Gujarat is 28.6005770114837\n",
            "Mape for Haryana is 19.841503458030093\n",
            "Mape for Himanchal_Pradesh is 22.735887516991376\n",
            "Mape for Jharkhand is 33.559017801001616\n",
            "Mape for Karnataka is 22.5363451582208\n",
            "Mape for Kerala is 8.517367238751463\n",
            "Mape for Madhya_Pradesh is 27.95267779030242\n",
            "Mape for Maharashtra is 19.613015521819854\n",
            "Mape for Manipur is 36.07555191169534\n",
            "Mape for Meghalaya is 51.88851515179407\n",
            "Mape for Mizoram is 58.12935327611595\n",
            "Mape for Nagaland is 61.9596380022987\n",
            "Mape for Odisha is 23.830565065966397\n",
            "Mape for Punjab is 20.049227664130516\n",
            "Mape for Rajasthan is 23.88149263551798\n",
            "Mape for Sikkim is 96.34302754865942\n",
            "Mape for Tamil_Nadu is 22.01417373235579\n",
            "Mape for Telangana is 43.701800575248534\n",
            "Mape for Tripura is 24.843338287805512\n",
            "Mape for Uttar_Pradesh is 17.013518669812917\n",
            "Mape for Uttarakhand is 15.885416090031187\n",
            "Mape for West_Bengal is 16.48020314823553\n",
            "Mape for Andaman is 79.71024352772015\n",
            "Mape for Chandigarh is 13.644726364977513\n",
            "Mape for Daman is 21.781456621440736\n",
            "Mape for Jammu is 19.42953130784081\n",
            "Mape for Ladakh is 17.472290115832294\n",
            "Mape for Lakshadweep is 100.0\n",
            "Mape for Delhi is 8.702690217545161\n",
            "Mape for Puducherry is 23.67261411478163\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([], dtype=int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ww9g2Qdq2zwl"
      },
      "source": [
        "# Bi-directional Peephole encoder-decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXxQyrpAxSpv",
        "outputId": "b90f6525-fcb4-4bed-aa88-eb31a4885de8"
      },
      "source": [
        "!pip install tensorflow-addons\n",
        "import tensorflow_addons as tfa\n",
        "encoder_inputs = tf.keras.layers.Input(shape=(n_past, n_features))\n",
        "encoder_l1 =  tf.keras.layers.Bidirectional(tf.keras.layers.RNN(tfa.rnn.PeepholeLSTMCell(32),return_sequences = True,return_state=True))\n",
        "encoder_outputs1 = encoder_l1(encoder_inputs)\n",
        "encoder_states1 = encoder_outputs1[1:]\n",
        "encoder_l2 =  tf.keras.layers.Bidirectional(tf.keras.layers.RNN( tfa.rnn.PeepholeLSTMCell(32),return_state=True))\n",
        "encoder_outputs2 = encoder_l2(encoder_outputs1[0])\n",
        "encoder_states2 = encoder_outputs2[1:]\n",
        "decoder_inputs = tf.keras.layers.RepeatVector(n_future)(encoder_outputs2[0])\n",
        "decoder_l1 =  tf.keras.layers.Bidirectional(tf.keras.layers.RNN(tfa.rnn.PeepholeLSTMCell(32),return_sequences = True))(decoder_inputs,initial_state = encoder_states1)\n",
        "decoder_l2 =  tf.keras.layers.Bidirectional(tf.keras.layers.RNN( tfa.rnn.PeepholeLSTMCell(32),return_sequences=True))(decoder_l1,initial_state = encoder_states2)\n",
        "decoder_outputs2 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1))(decoder_l2)\n",
        "model_e2d2 = tf.keras.models.Model(encoder_inputs,decoder_outputs2)\n",
        "model_e2d2.summary()\n",
        "!gdown --id 1-XU-T_fWIEUITd1bBFTz2x7QFUlJStgq\n",
        "model_e2d2.load_weights('/content/weights-5_28.4mape21_7.h5')\n",
        "\n",
        "# def mean_absolute_percentage_error2(y_true, y_pred): \n",
        "#     return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "# for epoch in range(100):\n",
        "#   epochno=epoch+27\n",
        "#   print(\"Epoch number: {}\".format(epochno))\n",
        "#   model_e2d2.compile(loss=tf.keras.losses.Huber(),optimizer=tf.optimizers.Adam(0.00001),\n",
        "#   metrics=[tf.keras.losses.MeanAbsolutePercentageError()], \n",
        "#                      run_eagerly=True)\n",
        "#   model_e2d2.fit(X_temptrain,Y_temptrain,batch_size=128, epochs=1)\n",
        "#   model_e2d2.save_weights(\"/content/drive/MyDrive/DST/weights-{}.h5\".format(epochno))\n",
        "#   predictions=model_e2d2.predict(X_temptest)\n",
        "#   print('Performance on test data: ',mean_absolute_percentage_error2(scaler.inverse_transform(predictions.reshape(-1,1)),\n",
        "#                                           scaler.inverse_transform(Y_temptest.reshape(-1,1))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (0.12.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Model: \"model_16\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_18 (InputLayer)           [(None, 21, 2)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_62 (Bidirectional [(None, 21, 64), (No 9152        input_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_63 (Bidirectional [(None, 64), (None,  25024       bidirectional_62[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_17 (RepeatVector) (None, 7, 64)        0           bidirectional_63[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_64 (Bidirectional (None, 7, 64)        25024       repeat_vector_17[0][0]           \n",
            "                                                                 bidirectional_62[0][1]           \n",
            "                                                                 bidirectional_62[0][2]           \n",
            "                                                                 bidirectional_62[0][3]           \n",
            "                                                                 bidirectional_62[0][4]           \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_65 (Bidirectional (None, 7, 64)        25024       bidirectional_64[0][0]           \n",
            "                                                                 bidirectional_63[0][1]           \n",
            "                                                                 bidirectional_63[0][2]           \n",
            "                                                                 bidirectional_63[0][3]           \n",
            "                                                                 bidirectional_63[0][4]           \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_16 (TimeDistri (None, 7, 1)         65          bidirectional_65[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 84,289\n",
            "Trainable params: 84,289\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-XU-T_fWIEUITd1bBFTz2x7QFUlJStgq\n",
            "To: /content/weights-5_28.4mape21_7.h5\n",
            "100% 392k/392k [00:00<00:00, 52.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUNdAEtemGeM",
        "outputId": "c41d2239-e925-43e3-e438-0d74c389b2c2"
      },
      "source": [
        "predictions=model_e2d2.predict(X_temptest)\n",
        "print('Performance on test data: ',mean_absolute_percentage_error2(scaler.inverse_transform(predictions.reshape(-1,1)),\n",
        "                                          scaler.inverse_transform(Y_temptest.reshape(-1,1))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performance on test data:  28.48894955502333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nnx8Tkc6gmtC"
      },
      "source": [
        "dicti ={\n",
        " 'Andhra_Pradesh':[0,13],\n",
        " 'Arunachal_Pradesh':[13,38],\n",
        " 'Assam':[38,71],\n",
        " 'Bihar':[71,109],\n",
        " 'Chattisgarh':[109,137],\n",
        " 'Goa':[137,139],\n",
        " 'Gujarat':[139,172],\n",
        " 'Haryana':[172,194],\n",
        " 'Himanchal_Pradesh':[194,206],\n",
        " 'Jharkhand':[206,230],\n",
        " 'Karnataka':[230,260],\n",
        " 'Kerala':[260,274],\n",
        " 'Madhya_Pradesh':[274,329],\n",
        " 'Maharashtra':[329,365],\n",
        " 'Manipur':[365,381],\n",
        " 'Meghalaya':[381,392],\n",
        " 'Mizoram':[392,400],\n",
        " 'Nagaland':[400,412],\n",
        " 'Odisha':[412,442],\n",
        " 'Punjab':[442,464],\n",
        " 'Rajasthan':[464,497],\n",
        " 'Sikkim':[497,501],\n",
        " 'Tamil_Nadu':[501,539],\n",
        " 'Telangana':[539,572],\n",
        " 'Tripura':[572,580],\n",
        " 'Uttar_Pradesh':[580,655],\n",
        " 'Uttarakhand':[655,668],\n",
        " 'West_Bengal':[668,691],\n",
        " 'Andaman':[691,694],\n",
        " 'Chandigarh':[694,695],\n",
        " 'Daman':[695,698],\n",
        " 'Jammu':[698,718],\n",
        " 'Ladakh':[718,720],\n",
        " 'Lakshadweep':[720,721],\n",
        " 'Delhi':[721,732],\n",
        " 'Puducherry':[732,736]}\n",
        "def mean_absolute_percentage_error(y_true, y_pred): \n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "l=[]\n",
        "predictions_rs =model_e2d2.predict(X_temptest)\n",
        "for key, value in dicti.items():\n",
        "  mapes=mean_absolute_percentage_error(scaler.inverse_transform(predictions[value[0]:value[1],:].reshape(-1,1)),\n",
        "                                          scaler.inverse_transform(Y_temptest[value[0]:value[1],:].reshape(-1,1)))\n",
        "  print('Mape for {} is {}'.format(key,mapes))\n",
        "np.sort(np.array(l).astype(int))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOAEkWgZcpMR",
        "outputId": "682c1b38-71c4-4923-87ea-5c0b4d60ab38"
      },
      "source": [
        "!git clone https://github.com/titu1994/Keras-Multiplicative-LSTM"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Keras-Multiplicative-LSTM'...\n",
            "remote: Enumerating objects: 27, done.\u001b[K\n",
            "remote: Total 27 (delta 0), reused 0 (delta 0), pack-reused 27\u001b[K\n",
            "Unpacking objects: 100% (27/27), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwxdLEbxtDPk"
      },
      "source": [
        "!pip install q keras==2.3.1\n",
        "!pip install tensorflow==1.14\n",
        "import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cxp6zH_jtSlB"
      },
      "source": [
        "import sys\n",
        "# insert at 1, 0 is the script path (or '' in REPL)\n",
        "sys.path.insert(1, '/content/Keras-Multiplicative-LSTM')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_iF2idUrwIK"
      },
      "source": [
        "from multiplicative_lstm import MultiplicativeLSTM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7T9RL4Fu-xE"
      },
      "source": [
        "X_train=np.load('/content/X_train.npy')\n",
        "Y_train=np.load('/content/Y_train.npy')\n",
        "X_test=np.load('/content/X_test.npy')\n",
        "Y_test=np.load('/content/Y_train.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdKOKfX0RozF"
      },
      "source": [
        "encoder_inputs = keras.layers.Input(shape=(n_past, n_features))\n",
        "encoder_l1 = keras.layers.Bidirectional(MultiplicativeLSTM( 32,return_sequences = True, return_state=True))\n",
        "encoder_outputs1 = encoder_l1(encoder_inputs)\n",
        "encoder_states1 = encoder_outputs1[1:]\n",
        "encoder_l2 = keras.layers.Bidirectional(MultiplicativeLSTM(32, return_state=True))\n",
        "encoder_outputs2 = encoder_l2(encoder_outputs1[0])\n",
        "encoder_states2 = encoder_outputs2[1:]\n",
        "decoder_inputs = keras.layers.RepeatVector(n_future)(encoder_outputs2[0])\n",
        "decoder_l1 =  keras.layers.Bidirectional(MultiplicativeLSTM(32, return_sequences=True))( decoder_inputs,initial_state = encoder_states1)\n",
        "decoder_l2 = keras.layers.Bidirectional(MultiplicativeLSTM(32, return_sequences=True ))(decoder_l1,initial_state = encoder_states2)\n",
        "decoder_outputs2 = keras.layers.TimeDistributed(keras.layers.Dense(1))(decoder_l2)\n",
        "model_e2d22 = keras.models.Model(encoder_inputs,decoder_outputs2)\n",
        "model_e2d22.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "RI_oncsjsYzw",
        "outputId": "4a766574-7233-4cf8-cbf1-3b0b746c28f1"
      },
      "source": [
        "encoder_inputs = keras.layers.Input(shape=(n_past, n_features))\n",
        "encoder_l1 = keras.layers.Bidirectional(MultiplicativeLSTM( 32,return_sequences = True, return_state=True))\n",
        "encoder_outputs1 = encoder_l1(encoder_inputs)\n",
        "encoder_states1 = encoder_outputs1[1:]\n",
        "encoder_l2 = keras.layers.Bidirectional(MultiplicativeLSTM(32, return_state=True))\n",
        "encoder_outputs2 = encoder_l2(encoder_outputs1[0])\n",
        "encoder_states2 = encoder_outputs2[1:]\n",
        "decoder_inputs = keras.layers.RepeatVector(n_future)(encoder_outputs2[0])\n",
        "\n",
        "decoder_l1 = MultiplicativeLSTM(32, return_sequences=True)(decoder_inputs,initial_state = encoder_states1)\n",
        "decoder_l2 = MultiplicativeLSTM(32, return_sequences=True )(decoder_l1,initial_state = encoder_states2)\n",
        "decoder_outputs2 = keras.layers.TimeDistributed(keras.layers.Dense(1))(decoder_l2)\n",
        "model_e2d22 = keras.models.Model(encoder_inputs,decoder_outputs2)\n",
        "model_e2d22.summary()\n",
        "# !gdown --id 1-XU-T_fWIEUITd1bBFTz2x7QFUlJStgq\n",
        "# model_e2d2.load_weights('/content/weights-5_28.4mape21_7.h5')\n",
        "def mean_absolute_percentage_error2(y_true, y_pred): \n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "for epoch in range(100):\n",
        "  epochno=epoch\n",
        "  print(\"Epoch number: {}\".format(epochno))\n",
        "  model_e2d22.compile(loss=keras.losses.Huber(),optimizer=keras.optimizers.Adam(0.0001),\n",
        "  metrics=[keras.losses.MeanAbsolutePercentageError()])\n",
        "  model_e2d22.fit(X_temptrain,Y_temptrain,batch_size=128, epochs=1)\n",
        "  # model_e2d22.save_weights(\"/content/drive/MyDrive/DST/weights-{}.h5\".format(epochno))\n",
        "  predictions=model_e2d22.predict(X_temptest)\n",
        "  print('Performance on test data: ',mean_absolute_percentage_error2(scaler.inverse_transform(predictions.reshape(-1,1)),\n",
        "                                          scaler.inverse_transform(Y_temptest.reshape(-1,1))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-7cf40e9a58a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdecoder_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRepeatVector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_future\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_outputs2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdecoder_l1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiplicativeLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitial_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_states1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mdecoder_l2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiplicativeLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_l1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitial_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_states2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdecoder_outputs2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeDistributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_l2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/legacy/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, **kwargs)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0;31m# Perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRecurrent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0;31m# Restore original input spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    328\u001b[0m                              \u001b[0;34m'but it received '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                              \u001b[0;34m' input tensors. Input received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m                              str(inputs))\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minput_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Layer multiplicative_lstm_30 expects 3 inputs, but it received 5 input tensors. Input received: [<tf.Tensor 'repeat_vector_8/Tile:0' shape=(?, 7, 64) dtype=float32>, <tf.Tensor 'bidirectional_4/while/Exit_3:0' shape=(?, 32) dtype=float32>, <tf.Tensor 'bidirectional_4/while/Exit_4:0' shape=(?, 32) dtype=float32>, <tf.Tensor 'bidirectional_4/while_1/Exit_3:0' shape=(?, 32) dtype=float32>, <tf.Tensor 'bidirectional_4/while_1/Exit_4:0' shape=(?, 32) dtype=float32>]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FVtpNDXwDMv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}